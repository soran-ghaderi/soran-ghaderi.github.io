---
layout: page
title: Skills And Expertise
permalink: /skills
comments: false
---


<div class="row justify-content-between">
<div class="col-md-8 pr-5">
    <section id="technical-skills">
        <h3>Technical Skills</h3>

        <div class="skill-category">
            <h4>Programming Languages</h4>
            <ul>
                <li><strong>Python:</strong> Experienced in machine learning, deep learning, and software development</li>
                <li><strong>C++:</strong> Intermediate knowledge with experience in algorithm implementation and briefly for computer vision</li>
            </ul>
        </div>

        <div class="skill-category">
            <h4>Machine Learning & Deep Learning</h4>
            <ul>
                <li><strong>Frameworks:</strong> PyTorch, TensorFlow, Keras</li>
                <li><strong>Libraries:</strong> NumPy, Pandas, Scikit-learn, Matplotlib</li>
                <li><strong>Specialized Tools (limited experience):</strong> NVIDIA TensorRT, CUDA</li>
            </ul>
        </div>

        <div class="skill-category">
            <h4>Software Engineering Skills</h4>
            <ul>
                <li>Open-source library development</li>
                <li>Agile methodologies (Kanban)</li>
                <li>Asynchronous and multiprocessing programming</li>
                <li>Git version control</li>
                <li>API integration and microservices architecture</li>
            </ul>
        </div>
    </section>

    <section id="projects">
        <h3>Open Source Projects & Contributions</h3>

        <div class="project">
            <h4>ML Libraries</h4>
            <ul>
                <li>Developed and deployed multiple Python libraries on PyPI, including TransformerX, Emgraph, and Bigraph</li>
                <li>Implemented modular, object-oriented architectures with comprehensive documentation and testing</li>
                <li>Actively engaged in open-source community through code reviews and collaborative development</li>
            </ul>
        </div>

        <div class="project">
            <h4>TASE: Telegram Music Search Engine</h4>
            <ul>
                <li>Built a scalable music search engine using Python</li>
                <li>Integrated technologies: Elasticsearch, Pyrogram, ArangoDB, RabbitMQ, Celery</li>
                <li>Implemented fault-tolerant microservices architecture</li>
            </ul>
        </div>
    </section>

    <section id="technical-writing">
        <h3>Technical Writing</h3>
        <ul>
            <li>Published influential articles on Medium and Towards Data Science</li>
            <li>Key Publications:
                <ul>
                    <li><a href="https://towardsdatascience.com/the-map-of-transformers-e14952226398">
                        The Map Of Transformers</a></li>
                    <li><a href="https://towardsdatascience.com/transformers-in-action-attention-is-all-you-need-ac10338a023a">
                            Transformers in Action: Attention Is All You Need</a></li>
                    <li><a href="https://towardsdatascience.com/rethinking-thinking-how-do-attention-mechanisms-actually-work-a6f67d313f99">
                        Rethinking Thinking: How Do Attention Mechanisms Actually Work?</a></li>
                </ul>
            </li>
        </ul>
    </section>

    <section id="languages-interests">
        <h3>Languages & Personal Interests</h3>
        <div class="languages">
<!--            <h4>Languages</h4>-->
            <p><strong>Languages</strong>: Fluent in English, Kurdish, and Persian.</p>
        </div>
        <div class="interests">
<!--            <h3></h3>-->
            <p><strong>Interests</strong>: I enjoy staying up-to-date on the latest developments in the field of artificial intelligence,
                and regularly read outstanding papers in the field. In my free time, I enjoy strolling around the city or hiking.</p>
        </div>
    </section>
<!--    <h3>Machine learning</h3>-->

<!--    <h4>Programming Languages</h4>-->
<!--    <ul>-->
<!--        <li><b>Python:</b> Proficient in developing Python-based solutions for machine learning and deep learning tasks,-->
<!--            including data pre-processing, feature engineering, and model development and evaluation.</li>-->
<!--        <li><b>C++:</b> Basic understanding of C++14, with experience using it for implementing computer vision-->
<!--            algorithms using OpenCV library. Also, Developed various algorithms for data processing and analysis using-->
<!--            C++98 in university coursework, including sorting, searching, and graph algorithms.</li>-->
<!--    </ul>-->
<!--    <h4>Deep learning frameworks</h4>-->
<!--    <ul>-->
<!--        <li><b>Tensorflow:</b> Mainly used it in different projects such as python libraries, CV, NLP projects.</li>-->
<!--        <li><b>Keras:</b> Used it along Tensorflow</li>-->
<!--        <li><b>Pytorch:</b> Brief experience in implementing a few models</li>-->
<!--        <li><b></b></li>-->
<!--    </ul>-->
<!--    <h4>Libraries</h4>-->
<!--    <ul>-->
<!--        <li><b>Numpy and Pandas:</b> Experience in using NumPy and Pandas for data manipulation, cleaning, and transformation.</li>-->
<!--        <li><b>Scikit-learn:</b> Experience with Scikit-learn for implementing supervised and unsupervised machine-->
<!--            learning algorithms for classification, regression, and clustering tasks. Experience mainly gained-->
<!--            through university coursework and a few standalone projects.-->
<!--        </li>-->
<!--        <li><b>Matplotlib:</b> Familiar with Matplotlib for data visualization and plotting.</li>-->
<!--    </ul>-->
<!--    <h4>Tools</h4>-->
<!--    <ul>-->
<!--        <li><b>NVIDIA TensorRT:</b> Basic understanding of using TensorRT to optimize deep learning models for inference on-->
<!--            NVIDIA GPUs.</li>-->
<!--        <li><b>CUDA:</b> Basic understanding of using CUDA for parallel computing and accelerating deep learning-->
<!--            algorithms.</li>-->
<!--        <li><b>Note:</b> Experience gained through different courses and a few personal projects.</li>-->
<!--    </ul>-->
<!--    <h3>Software engineering</h3>-->
<!--    <ul>-->
<!--        <li>Developed multiple open-source Python libraries on GitHub and deployed them on PyPI, including TransformerX,-->
<!--            Emgraph, and Bigraph. These libraries are actively downloaded and being used by users.</li>-->
<!--        <li>Designed and implemented the architecture for the libraries using best practices such as object-oriented-->
<!--            programming, modular design, and version control with Git.</li>-->
<!--        <li>Collaborated with other developers on GitHub to contribute to open-source projects and perform code-->
<!--            reviews for pull requests.</li>-->
<!--        <li>Developed a Telegram music search engine named TASE using Python, integrating various APIs and technologies-->
<!--            such as Elasticsearch, Pyrogram, and ArangoDB. Implemented a scalable and fault-tolerant architecture-->
<!--            using RabbitMQ and Celery.</li>-->
<!--        <li>Utilized agile development methodologies such as Kanban to manage project tasks and ensure timely delivery-->
<!--            of features.</li>-->
<!--        <li>Developed documentation and test cases for the libraries and the search engine, ensuring high code quality-->
<!--            and maintainability.</li>-->
<!--        <li>Developed high-performance web applications using asynchronous and multiprocessing programming techniques in-->
<!--            Python, leveraging libraries such as `multiprocessing`, `threading`, `ascyncio`, and `concurrent.futures`.</li>-->
<!--    </ul>-->

<!--    <h3>Technical Writing and AI Research Blog</h3>-->
<!--    <ul>-->
<!--        <li><b>Platforms:</b> Medium and Towards Data Science</li>-->
<!--        <li><b>Articles:</b> Authored and published articles on attention mechanisms and Transformers:-->
<!--            <ul>-->
<!--                <li><a href="https://towardsdatascience.com/the-map-of-transformers-e14952226398">-->
<!--                    The Map Of Transformers</a></li>-->
<!--                <li>-->
<!--                    <a href="https://towardsdatascience.com/transformers-in-action-attention-is-all-you-need-ac10338a023a">-->
<!--                        Transformers in Action: Attention Is All You Need</a></li>-->
<!--                <li><a href="https://towardsdatascience.com/rethinking-thinking-how-do-attention-mechanisms-actually-work-a6f67d313f99">-->
<!--                    Rethinking Thinking: How Do Attention Mechanisms Actually Work?</a></li>-->
<!--            </ul>-->
<!--        </li>-->
<!--        <li><b>Notes:</b> Conducted research and synthesized complex technical concepts into clear and accessible content for a broad audience.</li>-->
<!--    </ul>-->
<!--    <h3>Languages and Interests</h3>-->
<!--    <ul>-->
<!--        <li><b>Languages:</b> Fluent in English, Kurdish, and Persian.</li>-->
<!--        <li><b>Interests:</b> I enjoy staying up-to-date on the latest developments in the field of artificial-->
<!--            intelligence, and regularly read outstanding papers in the field. In my free time, I enjoy strolling around-->
<!--            the city or hiking.</li>-->
<!--    </ul>-->
        <hr>
        <section id="research-implementations">
            <h4>Other Experiences in Research Paper Re-implementations During Projects or Courses</h4>

            <div class="research-category">
                <h4>Computer Vision</h4>
                <ul>
                    <li>
                        <strong>Object Detection and Recognition</strong>
                        <ul>
                            <li>YOLO v3 for car detection and object localization (CVPR 2015)</li>
                            <li>ResNet50 for hand sign recognition (CVPR 2015)</li>
                            <li>Transfer learning and fine-tuning pretrained models for car recognition</li>
                        </ul>
                    </li>

                    <li>
                        <strong>Face Recognition</strong>
                        <ul>
                            <li>Inception network and FaceNet implementation</li>
                            <li>Face recognition embedding based on Schroff et al. (2015)</li>
                        </ul>
                    </li>

                    <li>
                        <strong>Generative Models</strong>
                        <ul>
                            <li>Neural style transfer (Gatys et al., 2015)</li>
                            <li>Volcanoes classification on Venus dataset</li>
                            <li>Fruit image generation using Variational Autoencoders</li>
                            <li>Partial implementation of <a href="https://github.com/soran-ghaderi/make-a-video" target="_blank">Make-A-Video</a>: Text-to-Video Generation (2022)</li>
                        </ul>
                    </li>
                </ul>
            </div>

            <div class="research-category">
                <h4>Natural Language Processing</h4>
                <ul>
                    <li>
                        <strong>Machine Translation</strong>
                        <ul>
                            <li>Neural machine translation using attention mechanisms</li>
                            <li>Transformer model implementation for French-to-English translation (using <a href="https://github.com/tensorops/TransformerX" target="_blank">TransformerX</a> library)</li>
                        </ul>
                    </li>

                    <li>
                        <strong>Text Generation and Classification</strong>
                        <ul>
                            <li>Fine-tuning TF-Hub pretrained models for text classification</li>
                            <li>Character-level text generation using RNNs</li>
                            <li>Word-level text generation (Shakespeare-style poem generation)</li>
                            <li>Sentiment classifier with emoji recommendation using LSTM and GloVe embeddings</li>
                            <li>Tweet emotion recognition</li>
                        </ul>
                    </li>

                    <li>
                        <strong>Embedding and Representation Learning</strong>
                        <ul>
                            <li>Sequence models with various embedding layers</li>
                            <li>Word vector representations (Word2Vec, GloVe)</li>
                            <li>Sequence models using attention mechanisms</li>
                        </ul>
                    </li>
                </ul>
            </div>

            <div class="research-category">
                <h4>Speech Processing</h4>
                <ul>
                    <li>Jazz solo improvisation using LSTM on music corpus</li>
                    <li>Deep learning for trigger word detection</li>
                </ul>
            </div>
        </section>
<!--    <h3>Paper Re-implementations</h3>-->
<!--    <h4>Computer vision</h4>-->
<!--    <ul>-->
<!--        <li><b>YOLO 3 for car detection and object localization</b>, Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You-->
<!--            Only Look Once: Unified, Real-Time Object Detection (2015), <a href="">#autonomous_driving</a></li>-->
<!--        <li><b>Resnet50 for hand sign recognition</b>, Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed,-->
<!--            S., Anguelov, D., Erhan, D., Vanhoucke, V., & Rabinovich, A. (2014). Going Deeper with Convolutions.,-->
<!--            Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - Deep Residual Learning for Image Recognition (2015)</li>-->
<!--        <li><b>Transfer learning and fine-tuning pretrained models for car recognition</b></li>-->
<!--        <li><b>Inception network, FaceNet in Face recognition</b>: Reimplementation of "Florian Schroff, Dmitry Kalenichenko, James Philbin (2015).-->
<!--            FaceNet: A Unified Embedding for Face Recognition and Clustering"</li>-->
<!--        <li><b>Neural style transfer</b>, "Leon A. Gatys, Alexander S. Ecker,-->
<!--            Matthias Bethge, (2015). A Neural Algorithm of Artistic Style", <a href="">#generative</a>, </li>-->
<!--        <li><b>Classifying volcanoes on Venus</b>, trained on volcanoes on Venus dataset (Pytorch)</li>-->
<!--        <li><b>Generating fruit image using variational autoencoders</b>, <a href="">#generative</a> </li>-->
<!--        <li><b><a href="https://github.com/soran-ghaderi/make-a-video" target="_blank">-->
<!--            Make a video</a></b> <i>(partially implemented - in-progress)</i>, Singer, U., Polyak, A., Hayes, T., Yin, X., An, J., Zhang, S., Hu, Q., Yang, H., Ashual,-->
<!--            O., Gafni, O., Parikh, D., Gupta, S.,& Taigman, Y. (2022). Make-A-Video: Text-to-Video Generation without-->
<!--            Text-Video Data. <a href="">#generative</a> </li>-->
<!--    </ul>-->
<!--    <h4>Natural Language Processing</h4>-->
<!--    <ul>-->
<!--        <li><b>Neural machine translation using Attention mechanisms</b></li>-->
<!--        <li><b>Neural machine translation (fr-to-en) using original Transformer model (Implemented using-->
<!--            <a href="https://github.com/tensorops/TransformerX" target="_blank">TransformerX</a> library)</b>,-->
<!--            Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin,-->
<!--            I. (2017). Attention Is All You Need.</li>-->
<!--        <li><b>Fine-tuning TF-hub pretrained models for text classification</b> and visualizing metrics using Tensorboard</li>-->
<!--        <li><b>Character-level text generation</b> using RNNs, <a href="">#generative</a> </li>-->
<!--        <li><b>Word-level text generation</b> using LSTM to generate poems in the style of Shakespeare, <a href="">#generative</a> </li>-->
<!--        <li>Trained sequence models using various embedding layers and word vector representations i.e. Word2Vec,-->
<!--            GloVe word vectors</li>-->
<!--        <li><b>Sentiment classifier using LSTM and GloVe-6B-50d word vector representations</b> for suggesting most relevant emojis regarding the input text,-->
<!--            trained on EMOJISET dataset</li>-->
<!--        <li><b>Trained sequence models using attention mechanisms</b></li>-->
<!--        <li><b>Tweet emotion recognition</b></li>-->
<!--    </ul>-->
<!--    <h4>Speech processing</h4>-->
<!--    <ul>-->
<!--        <li><b>Improvise Jazz solo</b> using an LSTM model trained on a corpus of Jazz music, <a href="">#generative</a> </li>-->
<!--        <li><b>Deep learning for trigger word detection</b></li>-->
<!--    </ul>-->


    <!--    <p class="mb-5"><img class="shadow-lg" src="{{site.url}}/assets/images/mediumish-jekyll-template.png" alt="jekyll template mediumish" /></p>-->

<!--    <p>This website is built with Jekyll and Mediumish template for Jekyll. It's for demonstration purposes, no real content can be found. Mediumish template for Jekyll is compatible with Github pages, in fact even this demo is created with Github Pages and hosted with Github.</p>-->


<!--<h4>Questions or bug reports?</h4>-->

<!--<p>Head over to our <a href="https://github.com/wowthemesnet/mediumish-theme-jekyll">Github repository</a>!</p>-->

</div>

<!--<div class="col-md-4">-->

<!--<div class="sticky-top sticky-top-80">-->
<!--<h5>Buy me a coffee</h5>-->

<!--<p>Thank you for your support! Your donation helps me to maintain and improve <a target="_blank" href="https://github.com/wowthemesnet/mediumish-theme-jekyll">Mediumish <i class="fab fa-github"></i></a>.</p>-->

<!--<a target="_blank" href="https://www.wowthemes.net/donate/" class="btn btn-danger">Buy me a coffee</a> <a target="_blank" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/" class="btn btn-warning">Documentation</a>-->

<!--</div>-->
<!--</div>-->
</div>
