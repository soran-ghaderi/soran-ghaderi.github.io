---
layout: post
title:  "TransformerX"
author: Soran Ghaderi

[//]: # (categories: [ library, python, machine learning, deep learning, transformers ])

image: images/transformerx.png
featured: true
hidden: true
comments: false
---

## Foreword
<b><a target="_blank" href="https://github.com/tensorops/TransformerX">TransformerX</a></b> is a Python library for building transformer-based models.

<img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/bi-graph/emgraph?style=social">
<img alt="PyPI - Python Version" src="https://img.shields.io/pypi/pyversions/emgraph">
<img alt="PyPI - Implementation" src="https://img.shields.io/pypi/implementation/transformerx">
<img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/tensorops/transformerx">
<img alt="PyPI - Maintenance" src="https://img.shields.io/badge/Maintained%3F-yes-green.svg">
<img alt="PyPI - License" src="https://img.shields.io/pypi/l/transformerx.svg">
<img alt="PyPI - Format" src="https://img.shields.io/pypi/format/transformerx.svg">
<img alt="Tensorflow 2" src="https://img.shields.io/badge/TensorFlow2-%23FF6F00.svg?style=flat&logo=TensorFlow&logoColor=white">

[//]: # (Glad to introduce my personal blog. Possibly, I will share what I read daily about deep learning, robotics, neuroscience, mathematics etc.)


## Abstract
TransformerX is an open-source Python library that provides a user-friendly interface to facilitate the construction 
of transformer-based models. It is aimed at researchers, students, and professionals seeking to develop, train, and 
evaluate transformers with ease. The library supports a range of transformer models, including the original 
Transformer among others. The development team is 
committed to continually enhancing the library's functionality, regularly adding new features and improvements to 
meet the needs of the research community. TransformerX seamlessly integrates with Tensorflow and will soon offer 
support for Pytorch and JAX. The library's documentation is extensive, featuring tutorials, examples, and technical 
details to assist users in understanding and effectively utilizing its capabilities.

---------------

## Features

<ul>
  <li><strong>Support CPU/GPU (CUDA cores):</strong> TransformerX is capable of running on both CPUs and GPUs with CUDA cores, making it a flexible choice for users with different hardware configurations.</li>
  <li><strong>Standard API:</strong> TransformerX adheres to a standard API, making it compatible with other libraries and frameworks that follow the same API. This facilitates ease of use and integration with existing workflows.</li>
  <li><strong>Well documented:</strong> TransformerX is extensively documented, featuring detailed documentation, tutorials, and examples to aid users in understanding and utilizing its functionality. This makes it easy for users to get started with the library and use it effectively.</li>
  <li><strong>Test driven development:</strong> TransformerX employs test driven development practices to ensure that the library is robust.</li>
  <li><strong>Support for Tensorflow 2 and other deep learning frameworks:</strong> TransformerX supports a range of deep learning frameworks, including Tensorflow 2, making it adaptable to a variety of use cases.</li>
  <li><strong>Open source:</strong> TransformerX is an open-source library, which means that it is free to use and can be accessed and modified by anyone. This makes it a collaborative effort and allows for community-driven development.</li>
  <li><strong>Customizable layers:</strong> It allows users to easily modify and customize the layers within transformer models to suit their specific needs. This gives users greater flexibility in their model design and can result in improved performance.</li>
</ul>

---------------


## Tech stack and contributions

<ul>
    <li>TensorFlow 2</li>
    <li>Numpy</li>
    <li>driven development (TDD)</li>
    <li>PyTest</li>
    <li>Sphinx</li>
    <li>Python</li>

</ul>

----------------

## Installation
<pre>$ pip install transformerx</pre>

<br> 

## Keywords
Deep-learning, Machine-learning, Transformers, Attention mechanisms, Algorithms, python library, TransformerX

[//]: # (I am holding a B.Eng. in computer eng. since 2018 and trying to learn new stuff in the mentioned areas whenever I have free time.)
[//]: # (During the past few years I've been working on different projects both in the industry and opensource.<br>)

[//]: # (<div>)

[//]: # (Some libraries and applications I've been involved in are as follows:)

[//]: # (<h4>Machine learning libraries</h4>)

[//]: # (<ul>)

[//]: # (<li><b>Emgraph</b>: A Python toolkit for knowledge graph embedding.)

[//]: # (<p>It helps the researchers to develop, evaluate, and benchmark their works easily. Currently, there are already a number of models implemented and more will be introduced shortly.)

[//]: # (At this time we're trying to optimize the underlying layers as well as simplifying the APIs even more.</p>)

[//]: # (</li>)

[//]: # (<li><b>Bigraph</b>: Bipartite-network link prediction in Python.</li>)

[//]: # (</ul>)

[//]: # ()
[//]: # (<h4>Applications</h4>)

[//]: # (<ul>)

[//]: # (<li><b>TASE: Telegram Audio Search Engine</b>: A lightning fast audio full-text search engine on top of Telegram</li>)

[//]: # (</ul>)

[//]: # (</div>)

[//]: # (<span class="spoiler">This post will be modified later.</span>)